{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reMo0fpMYmeK"
      },
      "source": [
        "# Tutorial 5: Langchain Agent\n",
        "\n",
        "In this tutorial we explore how to combine LangChain's modular interfaces with a robust C++ runtime, and the portability benefits of GenC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiexRlROXaW0"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "Before proceeding, please follow the instructions in\n",
        "[Tutorial 1](https://github.com/google/generative_computing/tree/master/generative_computing/docs/tutorials/tutorial_1_simple_cascade.ipynb)\n",
        "to set up your environment, connect Jupyter, and run the command below to run\n",
        "the GenC imports we're going to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1wi4ukBXakO"
      },
      "outputs": [],
      "source": [
        "import generative_computing.python as genc\n",
        "from generative_computing.python import authoring\n",
        "from generative_computing.python import interop\n",
        "from generative_computing.python import runtime\n",
        "from generative_computing.python.examples import executor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rsXhFqCe7uQ"
      },
      "source": [
        "Let's also import a few other packages we're going to use:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buIVFhbOYlh3"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "import langchain\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZoE0wvyZbY0"
      },
      "source": [
        "## Define Tools\n",
        "\n",
        "`WolframAlpha` is an example of a tool that could be used by a variety of\n",
        "agents. In order to promote its use as a tool within LangChain, you can derive\n",
        "from the `CustomTool` class we provide with GenC, as shown below. This class,\n",
        "defined in\n",
        "[custom_tool.py](https://github.com/google/generative_computing/tree/master/generative_computing/python/interop/langchain/custom_tool.py), inherits from the `LangChain`'s `tools.BaseTool`,\n",
        "and just makes provisions to include GenC code embedded with it.\n",
        "\n",
        "Note that the body of `computation` contains the IR you're already familiar\n",
        "with, we're just wrapping it in a way that facilitates composability with the\n",
        "external SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWw41hiFZnP-"
      },
      "outputs": [],
      "source": [
        "class WolframAlpha(genc.interop.langchain.CustomTool):\n",
        "  \"\"\"A specific implementation of CustomTool, including an appid for identification.\"\"\"\n",
        "\n",
        "  def __init__(self, appid: str):\n",
        "    name = \"WolframAlpha\"\n",
        "    description = (\n",
        "        \"https://products.wolframalpha.com/api/documentation, one capability is\"\n",
        "        \" to evaluate math expression.\"\n",
        "    )\n",
        "    # Extract math equation from a text, then calls WolfraAlpha\n",
        "    computation = (\n",
        "        genc.interop.langchain.CustomChain()\n",
        "        | genc.authoring.create_custom_function(\"/react/extract_math_question\")\n",
        "        | genc.authoring.create_wolfram_alpha(appid)\n",
        "        # Template Engine will extract the result from response JSON\n",
        "        | genc.authoring.create_inja_template(\n",
        "            \"{% if queryresult.pods\"\n",
        "            \" %}{{queryresult.pods.0.subpods.0.plaintext}}{% endif %}\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    super().__init__(\n",
        "        name=name, description=description, computation=computation\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtUSvTePZo_m"
      },
      "source": [
        "## Define Agent with Tool\n",
        "\n",
        "Now, let's define the agent proper.\n",
        "\n",
        "Similarly to what we did with the tool, here we use a GenC-supplied\n",
        "`CustomAgent` class that inherits from its LangChain base class counterpart,\n",
        "and makes provisions to include GenC code, such as the use of a GenC-defined\n",
        "model. This is defined in\n",
        "[custom_agent.py](https://github.com/google/generative_computing/tree/master/generative_computing/python/interop/langchain/custom_agent.py).\n",
        "\n",
        "In this example, we already moved the reusable agent/reasoning code into the\n",
        "LangChain-to-IR converter (see function `create_computation_from_agent`\n",
        "defined in\n",
        "[create_computation.py](https://github.com/google/generative_computing/tree/master/generative_computing/python/interop/langchain/create_computation.py),\n",
        "so you no longer need to write that - it's generatedand bundled-in\n",
        "automatically for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0g6-tb2aOOh"
      },
      "outputs": [],
      "source": [
        "class MathToolAgent(genc.interop.langchain.CustomAgent):\n",
        "  \"\"\"An agent that combines ReAct reasoning loop with WolframAlpha tools.\"\"\"\n",
        "\n",
        "  def __init__(self, appid: str, api_key: str):\n",
        "\n",
        "    system_instruction = \"\"\"\n",
        "    Solve a question answering task with interleaving Thought, Action,\n",
        "    Observation steps.\n",
        "    Thought can reason about the current situation\n",
        "    Action can be only two types:\n",
        "    (1) Math[query], Useful for when you need to solve math problems.\n",
        "    (2) Finish[answer], which returns the answer as a number terminates.\n",
        "    Here's an example:\n",
        "    Question: what is the result of power of 2 + 1?\n",
        "    Thought: power of 2\n",
        "    Action: Math[pow(2)]\n",
        "    Observation: 4\n",
        "    Thought: I can now process the answer.\n",
        "    Action: Math[4+1]\n",
        "    Observation: 5\n",
        "    Thought: Seems like I got the answer.\n",
        "    Action: Finish[5]\n",
        "    Please do it step by step.\n",
        "    Question: {question}\n",
        "    \"\"\"\n",
        "\n",
        "    tools = [WolframAlpha(appid)]\n",
        "\n",
        "    llm = genc.interop.langchain.CustomModel(\n",
        "        uri=\"/cloud/gemini\",\n",
        "        config=genc.interop.gemini.create_config(api_key),\n",
        "    )\n",
        "\n",
        "    # Init langchain.agents.agent.Agent with components backed by C++ runtime.\n",
        "    super().__init__(\n",
        "        llm_chain=langchain.chains.LLMChain(llm=llm, prompt=PromptTemplate(\n",
        "          input_variables=[\"query\"],\n",
        "          template=system_instruction)),\n",
        "        allowed_tools=[tool.name for tool in tools],\n",
        "        tools_list=tools,\n",
        "        max_iterations=8,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klHlbZtriYPP"
      },
      "source": [
        "\n",
        "This is all! As you can see, this is a lot more compact, you get to use an API\n",
        "you're familiar with, while at the same time being able to express the missing\n",
        "bits in GenC's native authoring API, and convert the logic into a portable IR\n",
        "that you can deploy in a variety of places (like what you've seen in the earlier\n",
        "tutorials).\n",
        "\n",
        "You can find all the code in an easy to run form in\n",
        "[langchain_agent_demo.py](https://github.com/google/generative_computing/tree/master/generative_computing/python/examples/langchain_agent_demo.py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2NimKdgarqH"
      },
      "source": [
        "## Compile \u0026 Run it\n",
        "\n",
        "Here's how it all comes together. Make sure to fill in the missing `app_id` and\n",
        "the `api_key` (as you did earlier)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlrhUT5XZasC"
      },
      "outputs": [],
      "source": [
        "wolfram_app_id=\"\"\n",
        "gemini_api_key=\"\"\n",
        "\n",
        "agent = MathToolAgent(wolfram_app_id, gemini_api_key)\n",
        "\n",
        "portable_ir = genc.interop.langchain.create_computation(agent)\n",
        "\n",
        "# To run it localy\n",
        "runner = genc.runtime.Runner(portable_ir,\n",
        "                             genc.examples.executor.create_default_executor())\n",
        "result = runner(\"\"\"\n",
        "  what is the result of (square root of 4) + 3 to the power of 2 + 3 *(8 +\n",
        "  4) / 2 - 7\"\"\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm82CsNya5uI"
      },
      "source": [
        "## Save the IR to a file and deploy on Android\n",
        "\n",
        "As in the preceding tutorials, the IR is, once again, portable, and can be\n",
        "deployed on the phone. You can print and save it to a file as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQOcgCt-Z-lk"
      },
      "outputs": [],
      "source": [
        "# Let's take a peak of how the IR or computation proto looks like\n",
        "print(portable_ir)\n",
        "\n",
        "with open(\"/tmp/genc_demo.pb\", \"wb\") as f:\n",
        "  f.write(portable_ir.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTy9BFfhuMWB"
      },
      "source": [
        "After that, you can follow the same process as in\n",
        "[Tutorial 1](https://github.com/google/generative_computing/tree/master/generative_computing/docs/tutorials/tutorial_1_simple_cascade.ipynb)\n",
        "to load it in the “Generative Computing Demo” app on your Android phone, and\n",
        "test it there.\n",
        "\n",
        "For example, you can type a math query like the one below:\n",
        "\n",
        "```What is the result of 6 * 9 + (square root of 4)```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUQ47iPzjjFF"
      },
      "source": [
        "This is the last tutorial currently included with GenC, but please stay tuned\n",
        "for more coming in the future!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
