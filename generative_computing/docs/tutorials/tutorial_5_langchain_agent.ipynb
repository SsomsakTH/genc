{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reMo0fpMYmeK"
      },
      "source": [
        "# Tutorial 5: Langchain Agent\n",
        "\n",
        "In this tutorial we explore how to combine Langchain's modular interfaces with a robust C++ runtime, that is portable to mobile also."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiexRlROXaW0"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "Before proceeding, please follow the\n",
        "[instructions](.../tutorial_1_simple_cascade.ipynb) in Tutorial 1 to set up your environment, connect Jupyter, and run the command below to run\n",
        "the GenC imports we're goign to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1wi4ukBXakO"
      },
      "outputs": [],
      "source": [
        "import generative_computing.python as genc\n",
        "from generative_computing.python import authoring\n",
        "from generative_computing.python import interop\n",
        "from generative_computing.python import runtime\n",
        "from generative_computing.python.examples import executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buIVFhbOYlh3"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "import langchain\n",
        "from langchain.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZoE0wvyZbY0"
      },
      "source": [
        "## Define Tools\n",
        "WolframAlpha is a Tool, therefore we wrap it under a LangChain Tool interface.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWw41hiFZnP-"
      },
      "outputs": [],
      "source": [
        "class WolframAlpha(genc.interop.langchain.CustomTool):\n",
        "  \"\"\"A specific implementation of CustomTool, including an appid for identification.\"\"\"\n",
        "\n",
        "  def __init__(self, appid: str):\n",
        "    name = \"WolframAlpha\"\n",
        "    description = (\n",
        "        \"https://products.wolframalpha.com/api/documentation, one capability is\"\n",
        "        \" to evaluate math expression.\"\n",
        "    )\n",
        "    # Extract math equation from a text, then calls WolfraAlpha\n",
        "    computation = (\n",
        "        genc.interop.langchain.CustomChain()\n",
        "        | genc.authoring.create_custom_function(\"/react/extract_math_question\")\n",
        "        | genc.authoring.create_wolfram_alpha(appid)\n",
        "        # Template Engine will extract the result from response JSON\n",
        "        | genc.authoring.create_inja_template(\n",
        "            \"{% if queryresult.pods\"\n",
        "            \" %}{{queryresult.pods.0.subpods.0.plaintext}}{% endif %}\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    super().__init__(\n",
        "        name=name, description=description, computation=computation\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtUSvTePZo_m"
      },
      "source": [
        "## Define Agent with Tool\n",
        "\n",
        "In this example, we already moved the reusable agent/reasoning code into a LangChain interopertor, so you no longer need to write that.\n",
        "\n",
        "In this section we explore how to take the prepackaged Agent to speed up your dev process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0g6-tb2aOOh"
      },
      "outputs": [],
      "source": [
        "class MathToolAgent(genc.interop.langchain.CustomAgent):\n",
        "  \"\"\"An agent that combines ReAct reasoning loop with WolframAlpha tools.\"\"\"\n",
        "\n",
        "  def __init__(self, appid: str, api_key: str):\n",
        "\n",
        "    system_instruction = \"\"\"\n",
        "    Solve a question answering task with interleaving Thought, Action,\n",
        "    Observation steps.\n",
        "    Thought can reason about the current situation\n",
        "    Action can be only two types:\n",
        "    (1) Math[query], Useful for when you need to solve math problems.\n",
        "    (2) Finish[answer], which returns the answer as a number terminates.\n",
        "    Here's an example:\n",
        "    Question: what is the result of power of 2 + 1?\n",
        "    Thought: power of 2\n",
        "    Action: Math[pow(2)]\n",
        "    Observation: 4\n",
        "    Thought: I can now process the answer.\n",
        "    Action: Math[4+1]\n",
        "    Observation: 5\n",
        "    Thought: Seems like I got the answer.\n",
        "    Action: Finish[5]\n",
        "    Please do it step by step.\n",
        "    Question: {question}\n",
        "    \"\"\"\n",
        "\n",
        "    tools = [WolframAlpha(appid)]\n",
        "\n",
        "    llm = genc.interop.langchain.CustomModel(\n",
        "        uri=\"/cloud/gemini\",\n",
        "        config=genc.interop.gemini.create_config(api_key),\n",
        "    )\n",
        "\n",
        "    # Init langchain.agents.agent.Agent with components backed by C++ runtime.\n",
        "    super().__init__(\n",
        "        llm_chain=langchain.chains.LLMChain(llm=llm, prompt=PromptTemplate(\n",
        "          input_variables=[\"query\"],\n",
        "          template=system_instruction)),\n",
        "        allowed_tools=[tool.name for tool in tools],\n",
        "        tools_list=tools,\n",
        "        max_iterations=8,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2NimKdgarqH"
      },
      "source": [
        "## Compile \u0026 Run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlrhUT5XZasC"
      },
      "outputs": [],
      "source": [
        "wolfram_app_id=\"\"\n",
        "gemini_api_key=\"\"\n",
        "\n",
        "agent = MathToolAgent(wolfram_app_id, gemini_api_key)\n",
        "\n",
        "portable_ir = genc.interop.langchain.create_computation(agent)\n",
        "\n",
        "# To run it localy\n",
        "runner = genc.runtime.Runner(portable_ir,\n",
        "                             genc.examples.executor.create_default_executor())\n",
        "result = runner(\"\"\"\n",
        "  what is the result of (square root of 4) + 3 to the power of 2 + 3 *(8 +\n",
        "  4) / 2 - 7\"\"\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm82CsNya5uI"
      },
      "source": [
        "## Save the IR to a file and deploy on Android\n",
        "\n",
        "IR stands for intermediate representation. GenC transforms the agent into a computation schema or proto, which is platform agnostic. Therefore we can directly load it on a platform with GenC runtime.\n",
        "\n",
        "1. Run following code to save the IR to a file.\n",
        "\n",
        "2. Follow instructions [here](.../tutorial_1_simple_cascadeipynb#scrollTo=GhLV1BlXt0fK) to deploy the IR on Android phone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQOcgCt-Z-lk"
      },
      "outputs": [],
      "source": [
        "# Let's take a peak of how the IR or computation proto looks like\n",
        "print(portable_ir)\n",
        "\n",
        "with open(\"/tmp/genc_demo.pb\", \"wb\") as f:\n",
        "  f.write(portable_ir.SerializeToString())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTy9BFfhuMWB"
      },
      "source": [
        "## Run the demo on Android\n",
        "\n",
        "Open the “Generative Computing Demo” app and type a math query.\n",
        "Sample query to enter in UI:\n",
        "\n",
        "```What is the result of 6 * 9 + (square root of 4)```\n",
        "\n",
        "See the result."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
