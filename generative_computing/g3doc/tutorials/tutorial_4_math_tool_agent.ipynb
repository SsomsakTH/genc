{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNUkaZyeP8y4"
      },
      "source": [
        "# Tutorial 4: Math Tool Agent\n",
        "\n",
        "Large Language Models (LLMs) can serve as orchestrators, often referred to as\n",
        "agents. In this tutorial, we will guide you step-by-step on how to blend\n",
        "reasoning with the practical use of tools using GenC.\n",
        "\n",
        "The `MathToolAgent` integrates reasoning with math tool, we will employ the\n",
        "following components:\n",
        "\n",
        "*   `ReAct` \u0026 `RepeatedConditionalChain` for facilitating the reasoning loop,\n",
        "    enabling dynamic decision-making.\n",
        "*   `RestCall`, accompanied by `parsers`, to illustrate making model calls and\n",
        "    handling json request \u0026 response.\n",
        "*   `LocalCache` is used to as a memory to recorde model interaction history.\n",
        "*   `WolframAlpha`, utilized as a tool for answering mathematical queries.\n",
        "\n",
        "This example is meant to demonstrate the essential ingredients to agents. For\n",
        "production more robust prompt engineering is necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbAo8YrPYpb1"
      },
      "source": [
        "## Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT-hwn-NymQM"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "import generative_computing as genc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FvZnLvGfP8y5"
      },
      "outputs": [],
      "source": [
        "gemini_api_key = \"\"\n",
        "wolfram_app_id = \"\"\n",
        "\n",
        "\n",
        "reasoning_template = \"\"\"\n",
        "  Solve a question answering task with interleaving Thought, Action, Observation steps.\n",
        "  Thought can reason about the current situation\n",
        "  Action can be only two types:\n",
        "  (1) Math[query], Useful for when you need to solve math problems.\n",
        "  (2) Finish[answer], which returns the answer as a number terminates.\n",
        "  Here's an example:\n",
        "  Question: what is the result of power of 2 + 1?\n",
        "  Thought: power of 2\n",
        "  Action: Math[pow(2)]\n",
        "  Observation: 4\n",
        "  Thought: I can now process the answer.\n",
        "  Action: Math[4+1]\n",
        "  Observation: 5\n",
        "  Thought: Seems like I got the answer.\n",
        "  Action: Finish[5]\n",
        "  Please do it step by step.\n",
        "  Question: {question}\n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRDbXnn0P8y5"
      },
      "source": [
        "## Define the Agent\n",
        "\n",
        "Agent behavior:\n",
        "\n",
        "*   Template Instruct the model to break down a question into steps\n",
        "*   Each step it explains its thought, and formulate a math equation as action\n",
        "*   The equation is then calculated by Wolfram.\n",
        "*   These interaction history are then stored in a memory/context\n",
        "*   Repeat for another step..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NVYM5CaOP8y5"
      },
      "outputs": [],
      "source": [
        "# Logger prints to terminal\n",
        "log_it = genc.authoring.create_logger()\n",
        "\n",
        "# Context keeps the interaction history with model.\n",
        "# These Context is backed by a thread safe key value store.\n",
        "read_context = genc.authoring.create_custom_function(\"/local_cache/read\")\n",
        "add_to_context = genc.authoring.create_custom_function(\"/local_cache/write\")\n",
        "evict_context = genc.authoring.create_custom_function(\"/local_cache/remove\")\n",
        "\n",
        "model_config = genc.authoring.create_rest_model_config(\n",
        "    \"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent\",\n",
        "    gemini_api_key,\n",
        ")\n",
        "model_call = genc.authoring.create_model_with_config(\n",
        "    \"/cloud/gemini\", model_config\n",
        ")\n",
        "\n",
        "# Use WolframAlpha as a Tool to solve simple math questions.\n",
        "solve_math = (\n",
        "    genc.interop.langchain.CustomChain()\n",
        "    | genc.authoring.create_custom_function(\"/react/extract_math_question\")\n",
        "    | genc.authoring.create_wolfram_alpha(wolfram_app_id)\n",
        "    # Template Engine will extract the result from response JSON\n",
        "    | genc.authoring.create_inja_template(\n",
        "        \"{% if queryresult.pods\"\n",
        "        \" %}{{queryresult.pods.0.subpods.0.plaintext}}{% endif %}\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Define a resoning loop\n",
        "# It will keep executing until a boolean op in the chain evaluates to true.\n",
        "reasoning_loop = (\n",
        "    genc.interop.langchain.CustomChain()\n",
        "    | read_context\n",
        "    | model_call\n",
        "    | genc.authoring.create_custom_function(\"/react/parse_thought_action\")\n",
        "    | log_it\n",
        "    | genc.authoring.create_regex_partial_match(\"Finish\")\n",
        "    | add_to_context\n",
        "    | solve_math\n",
        "    | genc.authoring.create_custom_function(\"/react/format_observation\")\n",
        "    | log_it\n",
        "    | add_to_context\n",
        ")\n",
        "# If agent can't get an answer by 8th iteration, terminate.\n",
        "reasoning_loop.num_iteration = 8\n",
        "\n",
        "# Now set up the instruction tempalte and wire the agent together.\n",
        "instruction_template = genc.authoring.create_prompt_template(\n",
        "    reasoning_template\n",
        ")\n",
        "\n",
        "math_agent_chain = (\n",
        "    genc.interop.langchain.CustomChain()\n",
        "    | evict_context\n",
        "    | instruction_template\n",
        "    | add_to_context\n",
        "    | log_it\n",
        "    | reasoning_loop\n",
        ")\n",
        "\n",
        "# Compiles the agent into a portable computation, which can be run in C++/mobile\n",
        "portable_ir = genc.interop.langchain.create_computation(math_agent_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIxSrngDYeYs"
      },
      "source": [
        "## Compile \u0026 Run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y3GlDvXaP8y6"
      },
      "outputs": [],
      "source": [
        "# Runs the agent\n",
        "runner = genc.runtime.Runner(portable_ir,\n",
        "                             genc.examples.executor.create_default_executor())\n",
        "runner(\n",
        "    \"\"\"what is the result of (square root of 4) + 3 to the power of 2 + 3 *(8 +\n",
        "     4) / 2 - 7\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyIzhQGVaESn"
      },
      "source": [
        "**Sample Output**\n",
        "\n",
        "*   Thought: I need to calculate the square root of 4 and cube 3 first.\n",
        "*   Action: Math[sqrt(4)]\n",
        "*   Observation: 2\n",
        "*   Thought: I need to cube 3 now.\n",
        "*   Action: Math[pow(3, 2)]\n",
        "*   Observation: 9\n",
        "*   Thought: Now I need to evaluate the expression.\n",
        "*   Action: Math[(2) + (9) + (3 * (8 + 4) / 2) - 7]\n",
        "*   Observation: 22\n",
        "*   Thought: Seems like I got the answer.\n",
        "*   Action: Finish[22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPveJnAkOyqy"
      },
      "source": [
        "## Save the IR to a file and deploy on Android\n",
        "\n",
        "1. Run following code to save the IR to a file.\n",
        "\n",
        "2. Follow instructions [here](.../tutorial_1_simple_cascadeipynb#scrollTo=GhLV1BlXt0fK) to deploy the IR on Android phone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVQGZ6cJPfcs"
      },
      "outputs": [],
      "source": [
        "from google3.pyglib import gfile\n",
        "\n",
        "with gfile.Open(\"/tmp/genc_demo.pb\", \"wb\") as f:\n",
        "  f.write(portable_ir.SerializeToString())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CeV81bYP3gg"
      },
      "source": [
        "## Run the demo on Android\n",
        "\n",
        "Open the “Generative Computing Demo” app and type a math query.\n",
        "Sample query to enter in UI:\n",
        "\n",
        "```What is the result of (square root of 4) + 3 to the power of 2```\n",
        "\n",
        "See the result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSqXKE3TeTQt"
      },
      "source": [
        "## Cross Language Interoperability\n",
        "\n",
        "*   The portable computation, can be run in C++ and Java\n",
        "*   Similar Chaining authoring interface is avaiable in C++, if you wish to\n",
        "    replicate this logic in C++, you can find a full example under cc/example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "civ2bTc9P8y6"
      },
      "source": [
        "## Intro to the next tutorial: Combine C++ Runtime with LangChain Interface\n",
        "\n",
        "In this tutorial we used GenC authoring interfaces, which transparently shows\n",
        "the exact logic under an agent.\n",
        "\n",
        "Developer may prefer other authoring framework such as LangChain. And you may\n",
        "have also noticed that the tools vary from use case to use case, but reasoning\n",
        "loop maybe reusable. How can we levarage the benefit of LangChain?\n",
        "\n",
        "In the next tutorial we'll demonstrate how the above code could be combined with\n",
        "LangChain interface to achieve both brevity of LangChain, robustness and\n",
        "transparency of GenC."
      ]
    }
  ],
  "metadata": {
    "colab": {
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
