{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reMo0fpMYmeK"
      },
      "source": [
        "# Tutorial 5: Langchain Agent\n",
        "\n",
        "In this tutorial we explore how to combine Langchain's modular interfaces with a robust C++ runtime, that is portable to mobile also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buIVFhbOYlh3"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "import langchain\n",
        "import generative_computing as genc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZoE0wvyZbY0"
      },
      "source": [
        "## Define Tools\n",
        "WolframAlpha is a Tool, therefore we wrap it under a LangChain Tool interface.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWw41hiFZnP-"
      },
      "outputs": [],
      "source": [
        "class WolframAlpha(genc.interop.langchain.CustomTool):\n",
        "  \"\"\"A specific implementation of CustomTool, including an appid for identification.\"\"\"\n",
        "\n",
        "  def __init__(self, appid: str):\n",
        "    super().__init__()\n",
        "    self.appid = appid\n",
        "    self.name = \"WolframAlpha\"\n",
        "    self.description = (\n",
        "        \"https://products.wolframalpha.com/api/documentation, one capability is\"\n",
        "        \" to evaluate math expression.\"\n",
        "    )\n",
        "    # Extract math equation from a text, then calls WolfraAlpha\n",
        "    self.computation = (\n",
        "        genc.interop.langchain.CustomChain()\n",
        "        | genc.authoring.create_custom_function(\"/react/extract_math_question\")\n",
        "        | genc.authoring.create_wolfram_alpha(appid)\n",
        "        # Template Engine will extract the result from response JSON\n",
        "        | genc.authoring.create_inja_template(\n",
        "            \"{% if queryresult.pods\"\n",
        "            \" %}{{queryresult.pods.0.subpods.0.plaintext}}{% endif %}\"\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtUSvTePZo_m"
      },
      "source": [
        "## Define Agent with Tool\n",
        "\n",
        "In this example, we already moved the reusable agent/reasoning code into a LangChain interopertor, so you no longer need to write that.\n",
        "\n",
        "In this section we explore how to take the prepackaged Agent to speed up your dev process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0g6-tb2aOOh"
      },
      "outputs": [],
      "source": [
        "class MathToolAgent(genc.interop.langchain.CustomAgent):\n",
        "  \"\"\"An agent that combines ReAct reasoning loop with WolframAlpha tools.\"\"\"\n",
        "\n",
        "  def __init__(self, appid: str):\n",
        "\n",
        "    system_instruction = textwrap.dedent(\"\"\"\n",
        "    Solve a question answering task with interleaving Thought, Action, Observation steps\n",
        "    Thought can reason about the current situation\n",
        "    Action can be only two types:\n",
        "    (1) Math[query], Useful for when you need to solve math problems.\n",
        "    (2) Finish[answer], which returns the answer as a number terminates.\n",
        "    Here's an example:\n",
        "    Question: what is the result of power of 2 + 1?\n",
        "    Thought: power of 2\n",
        "    Action: Math[pow(2)]\n",
        "    Observation: 4\n",
        "    Thought: I can now process the answer.\n",
        "    Action: Math[4+1]\n",
        "    Observation: 5\n",
        "    Thought: Seems like I got the answer.\n",
        "    Action: Finish[5]\n",
        "    Please do it step by step.\n",
        "    Question: {question}\"\"\")\n",
        "\n",
        "    prompt = langchain.prompts.PromptTemplate(\n",
        "        input_variables=[\"question\"], template=system_instruction\n",
        "    )\n",
        "    tools = [WolframAlpha(appid)]\n",
        "    # TODO(b/315872721): replace with CreateModelWithConfig\n",
        "    llm = genc.interop.langchain.CustomModel(uri=\"/ai_studio/gemini_pro\")\n",
        "\n",
        "    # Init langchain.agents.agent.Agent with components backed by C++ runtime.\n",
        "    super().__init__(\n",
        "        llm_chain=langchain.chains.LLMChain(llm=llm, prompt=prompt),\n",
        "        allowed_tools=[tool.name for tool in tools],\n",
        "        tools_list=tools,\n",
        "        max_iterations=5,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2NimKdgarqH"
      },
      "source": [
        "## Compile \u0026 Run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlrhUT5XZasC"
      },
      "outputs": [],
      "source": [
        "wolfram_app_id=\"\u003c\u003e\"\n",
        "agent = MathToolAgent(wolfram_app_id)\n",
        "\n",
        "portable_ir = genc.interop.langchain.create_computation(agent)\n",
        "\n",
        "# To run it localy\n",
        "runner = genc.runtime.Runner(portable_ir)\n",
        "result = runner(\n",
        "    \"what is the result of (square root of 4) + 3 to the power of 2 + 3 *(8 +\"\n",
        "    \" 4) / 2 - 7\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm82CsNya5uI"
      },
      "source": [
        "## Intro to next tutorial: Porting it to Mobile\n",
        "\n",
        "IR stands for intermediate representation. GenC transforms the agent into a computation schema or proto, which is platform agnostic. Therefore we can directly load it on a platform with GenC runtime. The next tutorial will show how this is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQOcgCt-Z-lk"
      },
      "outputs": [],
      "source": [
        "# Let's take a peak of how the IR or computation proto looks like\n",
        "portable_ir"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
