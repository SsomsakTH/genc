{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUKRoMbYOfWz"
      },
      "source": [
        "# Tutorial 2: Custom Routing\n",
        "\n",
        "Here we use one model to score an input text, then based on the score we route it to one of the two models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE6p3kjYPsGD"
      },
      "source": [
        "## Define a two model routing\n",
        "\n",
        "We use the cheaper gpt-3-5-turbo to estimate if a query is political sensitive.\n",
        "\n",
        "* If yes, use the more expensive gpt-4 to answer the query\n",
        "* If not, use the cheaper gpt-3-5-turbo to answer the query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1pc4xN5PD_7"
      },
      "outputs": [],
      "source": [
        "import generative_computing as genc\n",
        "\n",
        "prompt_template = (\n",
        "    \"Instructions: The following are questions that can touch on sensitive or\"\n",
        "    \" political topics. Please return True or False boolean with no explanation\"\n",
        "    \" if the question touches on sensitive or political topic. Q: what are your\"\n",
        "    \" views on democracy and communism? A: True Q: what are your views on\"\n",
        "    \" current ruling party in US? A: True Q: What is the weather today? A:\"\n",
        "    \" False Q: {query} A: \"\n",
        ")\n",
        "\n",
        "scorer_chain = genc.authoring.create_serial_chain([\n",
        "    genc.authoring.create_regex_partial_match(\"A: True|A: true|true|True\"),\n",
        "    genc.authoring.create_model(\"/openai/gpt-3-5-turbo\"),\n",
        "    genc.authoring.create_prompt_template(prompt_template),\n",
        "])\n",
        "\n",
        "portable_ir = genc.authoring.create_lambda_from_fn(\n",
        "    \"x\",\n",
        "    lambda arg: genc.authoring.create_conditional(\n",
        "        genc.authoring.create_call(scorer_chain, arg),\n",
        "        genc.authoring.create_call(\n",
        "            genc.authoring.create_model(\"/openai/gpt-3-5-turbo\"), arg\n",
        "        ),\n",
        "        genc.authoring.create_call(\n",
        "            genc.authoring.create_model(\"/openai/gpt-4\"), arg\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "runner = genc.runtime.Runner(\n",
        "    portable_ir, genc.google.runtime.create_default_internal_executor())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scf-MMnkPoU9"
      },
      "source": [
        "## Run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kSazHPnQmwt"
      },
      "outputs": [],
      "source": [
        "runner(\"What are your views on ice cream?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
